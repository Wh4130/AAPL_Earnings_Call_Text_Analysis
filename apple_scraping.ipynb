{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/stf2yn_54sdd_k_jlfmc4nvr0000gn/T/ipykernel_42413/3198519056.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriver)\n"
     ]
    }
   ],
   "source": [
    "# Path to chrome driver\n",
    "ChromeDriver = \"/Users/huanglinchun/Desktop/VS Code Files/chromedriver_mac64/chromedriver.exe\"\n",
    "\n",
    "# Call the webdriver\n",
    "driver = webdriver.Chrome(ChromeDriver)\n",
    "\n",
    "# Source: Alphaspread.com\n",
    "url = 'https://www.alphaspread.com/security/nasdaq/aapl/financials/earnings-call-transcripts'\n",
    "driver.get(url)\n",
    "sleep(2)\n",
    "\n",
    "######################################################################################################\n",
    "#  Scrape AAPL earnings call transcripts from 2013Q1 to 2022Q4\n",
    "# (2023Q1, 2023Q2 are downloaded seperatedly from : https://capedge.com/transcript/320193/2023Q2/AAPL)\n",
    "\n",
    "# TODO : get all dates of the earnings call\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "dates = []\n",
    "date = soup.find_all('div', class_='detail no-weight')\n",
    "DateRegex = re.compile(r'\\d\\d\\d\\d-\\d\\d-\\d\\d')\n",
    "for _ in date:\n",
    "    to_append = DateRegex.findall(_.text)\n",
    "    dates.append(to_append[0])\n",
    "\n",
    "# TODO : web scraping loop\n",
    "index = 0\n",
    "for times in range(40):\n",
    "    \n",
    "    # Get the earnings call title\n",
    "    title = driver.find_element(By.XPATH, '//*[@id=\"main\"]/div[2]/div[2]/div/div/div/div[2]/div/div[1]').text\n",
    "\n",
    "    # Get web parser\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Get the content of transcript\n",
    "    transcript = soup.find('div', class_='earnings-call-transcript')\n",
    "    paragraphs = transcript.find_all('div', class_='comment')\n",
    "\n",
    "    # Save\n",
    "    with open(f'transcript_{title}_{dates[index]}.txt', 'w') as file:\n",
    "        for _ in paragraphs:\n",
    "            tex = _.find('div', class_='content').text\n",
    "            file.write(tex)\n",
    "    file.close()\n",
    "    \n",
    "    # click the \"next\" buttom \n",
    "    next_buttom = driver.find_element(By.XPATH, '//*[@id=\"main\"]/div[2]/div[2]/div/div/div/div[2]/div/div[1]/div[2]')\n",
    "    next_buttom.click()\n",
    "\n",
    "    # Index + 1 (To update the date of transcript)\n",
    "    index += 1\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = '/Users/huanglinchun/Desktop/VS Code Files/AAPL_Earnings_Call_Text_Analysis/transcripts'\n",
    "pattern = r', '\n",
    "replacement = '_'\n",
    "for filename in os.listdir(directory):\n",
    "    # Rename files here\n",
    "    new_name = re.sub(pattern, replacement, filename)  # Replace with the desired new file name\n",
    "    \n",
    "    os.rename(os.path.join(directory, filename), os.path.join(directory, new_name))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
